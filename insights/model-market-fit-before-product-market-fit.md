---
title: "Model-market fit comes before product-market fit — without it, no amount of product excellence drives adoption"
description: "AI startups need a prerequisite layer beneath PMF: the capability threshold where models can actually satisfy market demands. Legal AI crossed it at 87% accuracy; finance AI at 56% hasn't — same demand, opposite outcomes."
topics: [business-models, future-of-ai-business]
source: "@nicbstme (Nicolas Bustamante) — Model-Market Fit"
date: 2026-02-28
---

Andreessen's 2007 principle — "market matters most" — still holds, but AI introduces a new variable: model capability. A great market only pulls product out of a startup when the underlying model can actually perform the required task. Without model-market fit, no amount of excellent design or strategy drives adoption.

The evidence is stark. Legal AI struggled for years despite massive market demand — BERT-era models couldn't handle the generation and reasoning lawyers needed. Then GPT-4 crossed the capability threshold in March 2023, and "Silicon Valley startups raised over hundreds of millions" within 18 months. Legal reasoning benchmarks now hit 87% accuracy. Finance AI? Same massive demand, but models only achieve 56.55% on financial analyst tasks. That 30-point gap is the difference between MMF present and MMF absent.

There's an accuracy cliff: "the gap between 80% and 99% accuracy is often infinite in practice." Regulated industries require near-perfect performance, not competent demos. This connects to [[build-for-obsolescence-models-eat-scaffolding]] — the capability gap creates a brutal dilemma: burn runway waiting for models to improve, or build workarounds that become obsolete when they do.

Bustamante offers a diagnostic test for whether you have MMF: remove all human correction from the loop. Would customers still pay? When MMF exists, human oversight *enhances* quality. When absent, it's compensatory — humans mask that the AI can't perform core tasks. This reframes [[context-is-the-product-not-the-model]]: context is your moat *only after* the model can do the job. Before that threshold, context engineering is premature optimization.

The strategic sequence is clear: MMF → PMF → Success. Skip the first step, and the second becomes impossible. The winners aren't first-movers — they're teams "prepared when the model capability threshold finally crossed."
